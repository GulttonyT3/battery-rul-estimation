{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c27929",
   "metadata": {},
   "source": [
    "# RUL estimation UNIBO Powertools Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fbed84-1a06-4ed2-8e47-36a72449ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import math\n",
    "import ntpath\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from importlib import reload\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, LayerNormalization, MultiHeadAttention, Conv1D, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM, Masking\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IS_COLAB = False\n",
    "IS_TRAINING = True\n",
    "RESULT_NAME = \"\"\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data_path = \"/content/drive/My Drive/battery-rul-estimation/experiments/\"\n",
    "else:\n",
    "    data_path = \"../../\"\n",
    "\n",
    "sys.path.append(data_path)\n",
    "from data_processing.unibo_powertools_data import UniboPowertoolsData, CycleCols\n",
    "from data_processing.model_data_handler import ModelDataHandler\n",
    "from data_processing.prepare_rul_data import RulHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690db4e1",
   "metadata": {},
   "source": [
    "### Config logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70583245-5d69-4da7-b029-9523aa55bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s [%(levelname)s]: %(message)s', level=logging.DEBUG, datefmt='%Y/%m/%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23174c62",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a235cd-1c0d-46d9-89cd-4194a2d2c967",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = UniboPowertoolsData(\n",
    "    test_types=[],\n",
    "    chunk_size=1000000,\n",
    "    lines=[37, 40],\n",
    "    charge_line=37,\n",
    "    discharge_line=40,\n",
    "    base_path=data_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6fc663-5714-4ba8-a29c-80ea2d04ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = [\n",
    "    '000-DM-3.0-4019-S',#minimum capacity 1.48\n",
    "    '001-DM-3.0-4019-S',#minimum capacity 1.81\n",
    "    '002-DM-3.0-4019-S',#minimum capacity 2.06\n",
    "\n",
    "    '009-DM-3.0-4019-H',#minimum capacity 1.41\n",
    "    '010-DM-3.0-4019-H',#minimum capacity 1.44\n",
    "\n",
    "    '014-DM-3.0-4019-P',#minimum capacity 1.7\n",
    "    '015-DM-3.0-4019-P',#minimum capacity 1.76\n",
    "    '016-DM-3.0-4019-P',#minimum capacity 1.56\n",
    "    '017-DM-3.0-4019-P',#minimum capacity 1.29\n",
    "    #'047-DM-3.0-4019-P',#new 1.98\n",
    "    #'049-DM-3.0-4019-P',#new 2.19\n",
    "\n",
    "\n",
    "\n",
    "    '007-EE-2.85-0820-S',#2.5\n",
    "    '008-EE-2.85-0820-S',#2.49\n",
    "    '042-EE-2.85-0820-S',#2.51\n",
    "\n",
    "    '043-EE-2.85-0820-H',#2.31\n",
    "\n",
    "\n",
    "    '040-DM-4.00-2320-S',#minimum capacity 3.75, cycles 188\n",
    "\n",
    "\n",
    "    '018-DP-2.00-1320-S',#minimum capacity 1.82\n",
    "    #'019-DP-2.00-1320-S',#minimum capacity 1.61\n",
    "    '036-DP-2.00-1720-S',#minimum capacity 1.91\n",
    "    '037-DP-2.00-1720-S',#minimum capacity 1.84\n",
    "    '038-DP-2.00-2420-S',#minimum capacity 1.854 (to 0)\n",
    "    '050-DP-2.00-4020-S',#new 1.81\n",
    "    '051-DP-2.00-4020-S',#new 1.866    \n",
    "    \n",
    "]\n",
    "\n",
    "test_names = [\n",
    "    '003-DM-3.0-4019-S',#minimum capacity 1.84\n",
    "\n",
    "    '011-DM-3.0-4019-H',#minimum capacity 1.36\n",
    "\n",
    "    '013-DM-3.0-4019-P',#minimum capacity 1.6\n",
    "\n",
    "\n",
    "\n",
    "    '006-EE-2.85-0820-S',# 2.621\n",
    "    \n",
    "    '044-EE-2.85-0820-H',# 2.43\n",
    "\n",
    "\n",
    "\n",
    "    '039-DP-2.00-2420-S',#minimum capacity 1.93\n",
    "\n",
    "\n",
    "\n",
    "    '041-DM-4.00-2320-S',#minimum capacity 3.76, cycles 190\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3fa4ff-1abb-43e4-9a38-93f4fef11948",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.prepare_data(train_names, test_names)\n",
    "dataset_handler = ModelDataHandler(dataset, [\n",
    "    CycleCols.VOLTAGE,\n",
    "    CycleCols.CURRENT,\n",
    "    CycleCols.TEMPERATURE\n",
    "])\n",
    "\n",
    "rul_handler = RulHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e58279d",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f0ac6-d09f-4ddc-b9ee-ccaac225d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPACITY_THRESHOLDS = {\n",
    "  3.0 : 2.7,#th 90% - min 2.1, 70%\n",
    "  2.85 : 2.7,#th 94.7% - min 2.622, 92%\n",
    "  2.0 : 1.93,#th 96.5% - min 1.93, 96.5%\n",
    "  4.0 : 3.77,#th 94.2% - min 3.77 94.2%\n",
    "  4.9 : 4.7,#th 95.9% - min 4.3, 87.7%\n",
    "  5.0 : 4.5#th 90% - min 3.63, 72.6%\n",
    "}\n",
    "N_CYCLE = 500\n",
    "WARMUP_TRAIN = 15\n",
    "WARMUP_TEST = 30\n",
    "\n",
    "(train_x, train_y_soh, test_x, test_y_soh,\n",
    "  train_battery_range, test_battery_range,\n",
    "  time_train, time_test, current_train, current_test) = dataset_handler.get_discharge_whole_cycle_future(train_names, test_names, min_cycle_length=300)\n",
    "\n",
    "# train_x = train_x[:,:284,:]\n",
    "# test_x = test_x[:,:284,:]\n",
    "# print(\"cut train shape {}\".format(train_x.shape))\n",
    "# print(\"cut test shape {}\".format(test_x.shape))\n",
    "\n",
    "train_y = rul_handler.prepare_y_future(train_names, train_battery_range, train_y_soh, current_train, time_train, CAPACITY_THRESHOLDS)\n",
    "del globals()[\"current_train\"]\n",
    "del globals()[\"time_train\"]\n",
    "test_y = rul_handler.prepare_y_future(test_names, test_battery_range, test_y_soh, current_test, time_test, CAPACITY_THRESHOLDS)\n",
    "del globals()[\"current_test\"]\n",
    "del globals()[\"time_test\"]\n",
    "\n",
    "x_norm = rul_handler.Normalization()\n",
    "x_norm.fit(train_x)\n",
    "\n",
    "train_x = x_norm.normalize(train_x)\n",
    "test_x = x_norm.normalize(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db54eeaf",
   "metadata": {},
   "source": [
    "## compressing x using autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94218966-2df7-4139-8aa6-483822b81ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOENCODER_WEIGHTS = '2022-02-11-17-51-06_autoencoder_gl_unibo_powertools'\n",
    "\n",
    "# Model definition\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "LATENT_DIM = 10\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        encoder_inputs = layers.Input(shape=(train_x.shape[1], train_x.shape[2]))\n",
    "        encoder_conv1 = layers.Conv1D(filters=8, kernel_size=10, strides=2, activation='relu', padding='same')(encoder_inputs)\n",
    "        encoder_pool1 = layers.MaxPooling1D(5, padding='same')(encoder_conv1)\n",
    "        encoder_conv2 = layers.Conv1D(filters=8, kernel_size=4, strides=1, activation='relu', padding='same')(encoder_pool1)\n",
    "        encoder_pool2 = layers.MaxPooling1D(3, padding='same')(encoder_conv2)\n",
    "        encoder_flat1 = layers.Flatten()(encoder_pool1)\n",
    "        encoder_flat2 = layers.Flatten()(encoder_pool2)\n",
    "        encoder_concat = layers.concatenate([encoder_flat1, encoder_flat2])\n",
    "        encoder_outputs = layers.Dense(self.latent_dim, activation='relu')(encoder_concat)\n",
    "        self.encoder = Model(inputs=encoder_inputs, outputs=encoder_outputs)\n",
    "\n",
    "        decoder_inputs = layers.Input(shape=(self.latent_dim,))\n",
    "        decoder_dense1 = layers.Dense(10*8, activation='relu')(decoder_inputs)\n",
    "        decoder_reshape1 = layers.Reshape((10, 8))(decoder_dense1)\n",
    "        decoder_upsample1 = layers.UpSampling1D(3)(decoder_reshape1)\n",
    "        decoder_convT1 = layers.Conv1DTranspose(filters=8, kernel_size=4, strides=1, activation='relu', padding='same')(decoder_upsample1)\n",
    "        decoder_upsample2 = layers.UpSampling1D(5)(decoder_convT1)\n",
    "        decoder_convT2 = layers.Conv1DTranspose(filters=8, kernel_size=10, strides=2, activation='relu', padding='same')(decoder_upsample2)\n",
    "        decoder_outputs = layers.Conv1D(3, kernel_size=3, activation='relu', padding='same')(decoder_convT2)\n",
    "        self.decoder = Model(inputs=decoder_inputs, outputs=decoder_outputs)\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "autoencoder = Autoencoder(LATENT_DIM)\n",
    "autoencoder.compile(optimizer=opt, loss='mse', metrics=['mse', 'mae', 'mape', tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "autoencoder.encoder.summary()\n",
    "autoencoder.decoder.summary()\n",
    "\n",
    "autoencoder.load_weights(data_path + 'results/trained_model/%s/model' % AUTOENCODER_WEIGHTS)\n",
    "\n",
    "\n",
    "# compression\n",
    "train_x = autoencoder.encoder(train_x).numpy()\n",
    "test_x = autoencoder.encoder(test_x).numpy()\n",
    "print(\"compressed train x shape {}\".format(train_x.shape))\n",
    "print(\"compressed test x shape {}\".format(test_x.shape))\n",
    "test_x = test_x[:,~np.all(train_x == 0, axis=0)]#we need same column number of training\n",
    "train_x = train_x[:,~np.all(train_x == 0, axis=0)]\n",
    "print(\"compressed train x shape without zero column {}\".format(train_x.shape))\n",
    "print(\"compressed test x shape without zero column {}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f868459c-ef08-492e-a7f1-df57c64ae156",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = rul_handler.Normalization()\n",
    "x_norm.fit(train_x)\n",
    "train_x = x_norm.normalize(train_x)\n",
    "test_x = x_norm.normalize(test_x)\n",
    "\n",
    "\n",
    "train_x = rul_handler.battery_life_to_time_series(train_x, N_CYCLE, train_battery_range)\n",
    "test_x = rul_handler.battery_life_to_time_series(test_x, N_CYCLE, test_battery_range)\n",
    "\n",
    "train_x, train_y, train_battery_range, train_y_soh = rul_handler.delete_initial(train_x, train_y, train_battery_range, train_y_soh, WARMUP_TRAIN)\n",
    "test_x, test_y, test_battery_range, test_y_soh = rul_handler.delete_initial(test_x, test_y, test_battery_range, test_y_soh, WARMUP_TEST)\n",
    "\n",
    "# first one is SOH, we keep only RUL\n",
    "train_y = train_y[:,1]\n",
    "test_y = test_y[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d7114c",
   "metadata": {},
   "source": [
    "# Y normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48931b71-42dd-4221-a3a1-099d0e09331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_norm = rul_handler.Normalization()\n",
    "y_norm.fit(train_y)\n",
    "train_y = y_norm.normalize(train_y)\n",
    "test_y = y_norm.normalize(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4053a277-2819-4c7b-a6c2-99c8d407375e",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cb1a58-2bf6-4c8b-a19d-1f991dfe3f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "N_HEADS = 8\n",
    "FF_DIM = 256\n",
    "N_BLOCKS = 6\n",
    "EMBED_DIM = 64\n",
    "BATCH_SIZE = 16\n",
    "DROPUT_RATE = 0.2\n",
    "SKIP_CONNECTION_STRENGTH = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a42d27-519f-4fad-81c1-3d5e8a476f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, feat_dim, num_heads, ff_dim, rate = 0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads = num_heads, key_dim = embed_dim)\n",
    "        self.ffn = keras.Sequential( [layers.Dense(ff_dim, activation = \"gelu\"), layers.Dense(feat_dim),] )\n",
    "        self.layernorm1 = layers.BatchNormalization()\n",
    "        self.layernorm2 = layers.BatchNormalization()\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training = training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training = training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4013f-0885-415e-a221-349be4bd1738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape):\n",
    "    inp = Input(input_shape)\n",
    "    x = inp\n",
    "\n",
    "    for k in range(N_BLOCKS):\n",
    "        x_old = x\n",
    "        transformer_block = TransformerBlock(EMBED_DIM, input_shape[-1], N_HEADS, FF_DIM, DROPUT_RATE)\n",
    "        x = transformer_block(x)\n",
    "        x = ((1.0 - SKIP_CONNECTION_STRENGTH) * x) + (SKIP_CONNECTION_STRENGTH * x_old)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dense(128, activation = \"selu\")(x)\n",
    "    x = layers.Dropout(DROPUT_RATE)(x)\n",
    "    x = Dense(1, activation = 'linear')(x)\n",
    "\n",
    "    out = x\n",
    "    model = Model(inp, out)\n",
    "    model.compile(tf.keras.optimizers.Adam(0.001), 'mae', metrics = [smape, 'mse', 'mae', 'mape', tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "    return model\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    y_true, y_pred = tf.cast(y_true, tf.float64), tf.cast(y_pred, tf.float64)\n",
    "    return 1 / len(y_true) * tf.reduce_sum(2 * tf.abs(y_pred - y_true) / (tf.abs(y_true) + tf.abs(y_pred)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9808875-c660-4f78-86a9-817761ae0828",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_TRAINING:\n",
    "  EXPERIMENT = \"lg_autoencoder_transformer_rul_unibo_powertools\"\n",
    "  \n",
    "  experiment_name = time.strftime(\"%Y-%m-%d-%H-%M-%S\") + '_' + EXPERIMENT\n",
    "  print(experiment_name)\n",
    "\n",
    "  model = get_model(train_x.shape[1:])\n",
    "  model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba9eda-a828-4baf-8ec1-379ea1706703",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_TRAINING:\n",
    "  history = model.fit(train_x, train_y, epochs = EPOCHS, batch_size = BATCH_SIZE, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f56046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_TRAINING:\n",
    "  model.save_weights(data_path + f'results/trained_model/{experiment_name}.h5')\n",
    "\n",
    "  hist_df = pd.DataFrame(history.history)\n",
    "  hist_csv_file = data_path + 'results/trained_model/%s_history.csv' % experiment_name\n",
    "  with open(hist_csv_file, mode='w') as f:\n",
    "      hist_df.to_csv(f)\n",
    "  history = history.history\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eeda1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_TRAINING:\n",
    "  history = pd.read_csv(data_path + 'results/trained_model/%s_history.csv' % RESULT_NAME)\n",
    "  model = keras.models.load_model(data_path + 'results/trained_model/%s.h5' % RESULT_NAME)\n",
    "  model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c58e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_TRAINING:\n",
    "  with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7696a5f8",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48845b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_x, test_y, return_dict = True)\n",
    "print(results)\n",
    "max_rmse = 0\n",
    "for index in range(test_x.shape[0]):\n",
    "    result = model.evaluate(np.array([test_x[index, :, :]]), np.array([test_y[index]]), return_dict = True, verbose=0)\n",
    "    max_rmse = max(max_rmse, result['rmse'])\n",
    "print(\"Max rmse: {}\".format(max_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182ee143",
   "metadata": {},
   "source": [
    "# Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb50dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=history['loss'],\n",
    "                    mode='lines', name='train'))\n",
    "if 'val_loss' in history:\n",
    "    fig.add_trace(go.Scatter(y=history['val_loss'],\n",
    "                    mode='lines', name='validation'))\n",
    "fig.update_layout(title='Loss trend',\n",
    "                  xaxis_title='epoch',\n",
    "                  yaxis_title='loss',\n",
    "                  width=1400,\n",
    "                  height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dbb700",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(train_x)\n",
    "\n",
    "train_y = y_norm.denormalize(train_y)\n",
    "train_predictions = y_norm.denormalize(train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357921ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for b in train_battery_range:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=train_y_soh[a:b], y=train_predictions[a:b,0],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(x=train_y_soh[a:b], y=train_y[a:b],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on training',\n",
    "                    xaxis_title='SoH Capacity',\n",
    "                    yaxis_title='Remaining Ah until EOL',\n",
    "                    xaxis={'autorange':'reversed'},\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()\n",
    "    a = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for b in train_battery_range:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=train_predictions[a:b,0],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=train_y[a:b],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on training',\n",
    "                    xaxis_title='Cycle',\n",
    "                    yaxis_title='Remaining Ah until EOL',\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()\n",
    "    a = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b7f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_x)\n",
    "\n",
    "test_y = y_norm.denormalize(test_y)\n",
    "test_predictions = y_norm.denormalize(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74878c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for b in test_battery_range:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=test_y_soh[a:b], y=test_predictions[a:b,0],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(x = test_y_soh[a:b], y=test_y[a:b],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on testing',\n",
    "                    xaxis_title='SoH Capacity',\n",
    "                    yaxis_title='Remaining Ah until EOL',\n",
    "                    xaxis={'autorange':'reversed'},\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()\n",
    "    a = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021de5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for b in test_battery_range:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=test_predictions[a:b, 0],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=test_y[a:b],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on testing',\n",
    "                    xaxis_title='Cycle',\n",
    "                    yaxis_title='Remaining Ah until EOL',\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()\n",
    "    a = b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
