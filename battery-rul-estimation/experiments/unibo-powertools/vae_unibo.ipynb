{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jw9FMur02UtZ"
   },
   "source": [
    "# Autoencoder UNIBO Powertools Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKxZ90kO2Uta"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from importlib import reload\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "IS_COLAB = False\n",
    "IS_TRAINING = True\n",
    "RESULT_NAME = \"\"\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data_path = \"/content/drive/My Drive/battery-rul-estimation/experiments/\"\n",
    "else:\n",
    "    data_path = \"../../\"\n",
    "\n",
    "sys.path.append(data_path)\n",
    "from data_processing.unibo_powertools_data import UniboPowertoolsData, CycleCols\n",
    "from data_processing.model_data_handler import ModelDataHandler\n",
    "from data_processing.prepare_rul_data import RulHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfVCRISs2Utc"
   },
   "source": [
    "### Config logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2IvySBk2Utd"
   },
   "outputs": [],
   "source": [
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s [%(levelname)s]: %(message)s', level=logging.DEBUG, datefmt='%Y/%m/%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsbkwTX22Utf"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrHYRy-a2Utg"
   },
   "outputs": [],
   "source": [
    "dataset = UniboPowertoolsData(\n",
    "    test_types=[],\n",
    "    chunk_size=1000000,\n",
    "    lines=[37, 40],\n",
    "    charge_line=37,\n",
    "    discharge_line=40,\n",
    "    base_path=data_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSFp-2Rl2Utj"
   },
   "outputs": [],
   "source": [
    "train_names = [\n",
    "    '000-DM-3.0-4019-S',#minimum capacity 1.48\n",
    "    '001-DM-3.0-4019-S',#minimum capacity 1.81\n",
    "    '002-DM-3.0-4019-S',#minimum capacity 2.06\n",
    "\n",
    "    '009-DM-3.0-4019-H',#minimum capacity 1.41\n",
    "    '010-DM-3.0-4019-H',#minimum capacity 1.44\n",
    "\n",
    "    '014-DM-3.0-4019-P',#minimum capacity 1.7\n",
    "    '015-DM-3.0-4019-P',#minimum capacity 1.76\n",
    "    '016-DM-3.0-4019-P',#minimum capacity 1.56\n",
    "    '017-DM-3.0-4019-P',#minimum capacity 1.29\n",
    "    #'047-DM-3.0-4019-P',#new 1.98\n",
    "    #'049-DM-3.0-4019-P',#new 2.19\n",
    "\n",
    "\n",
    "\n",
    "    '007-EE-2.85-0820-S',#2.5\n",
    "    '008-EE-2.85-0820-S',#2.49\n",
    "    '042-EE-2.85-0820-S',#2.51\n",
    "\n",
    "    '043-EE-2.85-0820-H',#2.31\n",
    "\n",
    "\n",
    "    '040-DM-4.00-2320-S',#minimum capacity 3.75, cycles 188\n",
    "\n",
    "\n",
    "    '018-DP-2.00-1320-S',#minimum capacity 1.82\n",
    "    #'019-DP-2.00-1320-S',#minimum capacity 1.61\n",
    "    '036-DP-2.00-1720-S',#minimum capacity 1.91\n",
    "    '037-DP-2.00-1720-S',#minimum capacity 1.84\n",
    "    '038-DP-2.00-2420-S',#minimum capacity 1.854 (to 0)\n",
    "    '050-DP-2.00-4020-S',#new 1.81\n",
    "    '051-DP-2.00-4020-S',#new 1.866    \n",
    "    \n",
    "]\n",
    "\n",
    "test_names = [\n",
    "    '003-DM-3.0-4019-S',#minimum capacity 1.84\n",
    "\n",
    "    '011-DM-3.0-4019-H',#minimum capacity 1.36\n",
    "\n",
    "    '013-DM-3.0-4019-P',#minimum capacity 1.6\n",
    "\n",
    "\n",
    "\n",
    "    '006-EE-2.85-0820-S',# 2.621\n",
    "    \n",
    "    '044-EE-2.85-0820-H',# 2.43\n",
    "\n",
    "\n",
    "\n",
    "    '039-DP-2.00-2420-S',#minimum capacity 1.93\n",
    "\n",
    "\n",
    "\n",
    "    '041-DM-4.00-2320-S',#minimum capacity 3.76, cycles 190\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-yTrXQ12Utm"
   },
   "outputs": [],
   "source": [
    "dataset.prepare_data(train_names, test_names)\n",
    "dataset_handler = ModelDataHandler(dataset, [\n",
    "    CycleCols.VOLTAGE,\n",
    "    CycleCols.CURRENT,\n",
    "    CycleCols.TEMPERATURE\n",
    "])\n",
    "\n",
    "rul_handler = RulHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAAxueIqkZM9"
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbntMzBZkZM9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train_x, train_y_soh, test_x, test_y_soh,\n",
    "  train_battery_range, test_battery_range,\n",
    "  time_train, time_test, current_train, current_test) = dataset_handler.get_discharge_whole_cycle_future(train_names, test_names)\n",
    "\n",
    "train_x = train_x[:,:284,:]\n",
    "test_x = test_x[:,:284,:]\n",
    "print(\"cut train shape {}\".format(train_x.shape))\n",
    "print(\"cut test shape {}\".format(test_x.shape))\n",
    "\n",
    "\n",
    "x_norm = rul_handler.Normalization()\n",
    "train_x, test_x = x_norm.fit_and_normalize(train_x, test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iYU-n0K2Utq"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSx96n4w2Uts"
   },
   "outputs": [],
   "source": [
    "if IS_TRAINING:\n",
    "    EXPERIMENT = \"autoencoder_unibo_powertools\"\n",
    "\n",
    "    experiment_name = time.strftime(\"%Y-%m-%d-%H-%M-%S\") + '_' + EXPERIMENT\n",
    "    print(experiment_name)\n",
    "\n",
    "# Model definition\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "LATENT_DIM = 3\n",
    "BATCH = 8\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(train_x.shape[1], train_x.shape[2])),\n",
    "            #layers.MaxPooling1D(5, padding='same'),\n",
    "            layers.Conv1D(filters=32, kernel_size=5, strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv1D(filters=16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(self.latent_dim + self.latent_dim, activation='relu')\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(self.latent_dim)),\n",
    "            layers.Dense(71 * 16, activation='relu'),\n",
    "            layers.Reshape((71, 16)),\n",
    "            layers.Conv1DTranspose(filters=16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv1DTranspose(filters=32, kernel_size=5, strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv1D(3, kernel_size=3, activation='relu', padding='same'),\n",
    "            #layers.UpSampling1D(5),\n",
    "        ])\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(tf.shape(mean))\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits\n",
    "\n",
    "    def call(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        decoded = self.decode(z)\n",
    "        return decoded\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x, _ = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss, decoded = self.compute_loss(x)\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        self.compiled_metrics.update_state(x, decoded)\n",
    "        metrics = {m.name: m.result() for m in self.metrics}\n",
    "        metrics['loss'] = loss\n",
    "        return metrics\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        x, _ = data\n",
    "        loss, decoded = self.compute_loss(x)\n",
    "        self.compiled_metrics.update_state(x, decoded)\n",
    "        metrics = {m.name: m.result() for m in self.metrics}\n",
    "        metrics['loss'] = loss\n",
    "        return metrics\n",
    "\n",
    "    def compute_loss(self, x):\n",
    "        def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "            log2pi = tf.math.log(2. * np.pi)\n",
    "            return tf.reduce_sum(\n",
    "                -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "                axis=raxis)\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        x_logit = self.decode(z)\n",
    "        cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "        logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2])\n",
    "        logpz = log_normal_pdf(z, 0., 0.)\n",
    "        logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "        return -tf.reduce_mean(logpx_z + logpz - logqz_x), x_logit\n",
    "\n",
    "autoencoder = VAE(LATENT_DIM)\n",
    "autoencoder.compile(optimizer=opt, metrics=['mse', 'mae', 'mape', tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "autoencoder.encoder.summary()\n",
    "autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIEcv6Ey2Utu"
   },
   "outputs": [],
   "source": [
    "if IS_TRAINING:\n",
    "    history = autoencoder.fit(train_x, train_x,\n",
    "                                epochs=500, \n",
    "                                batch_size=BATCH, \n",
    "                                verbose=1,\n",
    "                                validation_split=0.1\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNHlqcvP2Utx"
   },
   "outputs": [],
   "source": [
    "if IS_TRAINING:\n",
    "    autoencoder.save_weights(data_path + 'results/trained_model/%s/model' % experiment_name)\n",
    "\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_csv_file = data_path + 'results/trained_model/%s/history.csv' % experiment_name\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "    history = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_TRAINING:\n",
    "    history = pd.read_csv(data_path + 'results/trained_model/%s/history.csv' % RESULT_NAME)\n",
    "    autoencoder.load_weights(data_path + 'results/trained_model/%s/model' % RESULT_NAME)\n",
    "    autoencoder.encoder.summary()\n",
    "    autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_TRAINING:\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LH5RANQIEQVx"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggNKW-VqENFN"
   },
   "outputs": [],
   "source": [
    "results = autoencoder.evaluate(test_x, test_x, return_dict = True)\n",
    "print(results)\n",
    "max_rmse = 0\n",
    "for index in range(test_x.shape[0]):\n",
    "    result = autoencoder.evaluate(np.array([test_x[index, :, :]]), np.array([test_x[index, :, :]]), return_dict = True, verbose=0)\n",
    "    max_rmse = max(max_rmse, result['rmse'])\n",
    "print(\"Max rmse: {}\".format(max_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiqyD8Bn2Utz"
   },
   "source": [
    "# Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jH9RrBRN2Utz"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=history['loss'],\n",
    "                    mode='lines', name='train'))\n",
    "if 'val_loss' in history:\n",
    "    fig.add_trace(go.Scatter(y=history['val_loss'],\n",
    "                    mode='lines', name='validation'))\n",
    "fig.update_layout(title='Loss trend',\n",
    "                  xaxis_title='epoch',\n",
    "                  yaxis_title='loss',\n",
    "                  width=1400,\n",
    "                  height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = autoencoder.predict(train_x)\n",
    "labels = ['Voltage', 'Current', 'Temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_x.shape[2]):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=train_predictions[0,:,i],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=train_x[0,:,i],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on training - battery new',\n",
    "                    xaxis_title='Step',\n",
    "                    yaxis_title=labels[i],\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_x.shape[2]):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=train_predictions[int(train_battery_range[0]/2),:,i],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=train_x[int(train_battery_range[0]/2),:,i],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on training - middle life',\n",
    "                    xaxis_title='Step',\n",
    "                    yaxis_title=labels[i],\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_x.shape[2]):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=train_predictions[train_battery_range[0]-1,:,i],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=train_x[train_battery_range[0]-1,:,i],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on training - end of life',\n",
    "                    xaxis_title='Step',\n",
    "                    yaxis_title=labels[i],\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = autoencoder.predict(test_x)\n",
    "labels = ['Voltage', 'Current', 'Temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_x.shape[2]):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=test_predictions[0,:,i],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=test_x[0,:,i],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on testing - battery new',\n",
    "                    xaxis_title='Step',\n",
    "                    yaxis_title=labels[i],\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_x.shape[2]):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=test_predictions[int(test_battery_range[0]/2),:,i],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=test_x[0,:,i],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on testing - middle life',\n",
    "                    xaxis_title='Step',\n",
    "                    yaxis_title=labels[i],\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_x.shape[2]):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=test_predictions[test_battery_range[0]-1,:,i],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=test_x[0,:,i],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on testing - end of life',\n",
    "                    xaxis_title='Step',\n",
    "                    yaxis_title=labels[i],\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm_soh_prediction_only_future.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
